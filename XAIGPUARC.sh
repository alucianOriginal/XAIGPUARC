#!/bin/bash

#https://youtu.be/MBptqDzm8Hs
#|XAIGPUARC|cij‚Äã=k=1‚àën‚Äãaik‚Äã‚ãÖbkj‚Äã|f(xi‚Äã)=‚àëexj‚Äãexi|ExtremeLucyF16-1.7B.gguf65kCTX512KBatchsizeNpredigt|‚úÖ|
#No Cherry Picking MathTutor-7B-F17.gguf Demo with XAIGPUARC on A770LE16GiB:
#First:
#... (truncated)

#cij = ‚àëk=1n aik ‚ãÖ bkj; optimize with SYCL kernel, use FP16 32-bit precision for alignment and zero-copy focus.

#[ Prompt: 1080,3 t/s | Generation: 13,2 t/s ]

#> >>> CHAT HERE! ENTER ANSWER > CHAT ENTER ANSWER > CHAT
#Second:
#... (truncated)
#cij = ‚àëk=1n aik ‚ãÖ bkj; optimize with SYCL, use FP16 32-bit precision, focus on zero-copy alignment.

#[ Prompt: 1202,1 t/s | Generation: 13,6 t/s ]

#> CHAT HERE! ENTER ANSWER > CHAT ENTER ANSWER > CHAT
#Third:
#|? ... (truncated)

#cij = ‚àëk=1n aik ‚ãÖ bkj; optimize with SYCL; use FP16 32-bit precision; focus on zero-copy alignment.

#[ Prompt: 1163,3 t/s | Generation: 13,6 t/s ]
#> >>> CHAT HERE! ENTER ANSWER > CHAT ENTER ANSWER > CHAT
#Four:

#|? ... (truncated)

#cij‚Äã = ‚àëk=1n‚Äãaik‚Äã‚ãÖbkj‚Äã; SYCL kernel for optimization; use FP16 32-bit precision; focus on zero-copy alignment.

#[ Prompt: 1183,8 t/s | Generation: 13,5 t/s ]

#> #> CHAT HERE! ENTER ANSWER > CHAT ENTER ANSWER > CHAT

#Five:
#|? ... (truncated)

#cij‚Äã = ‚àëk=1n‚Äãaik‚Äã‚ãÖbkj‚Äã; optimize with SYCL for FP16 32-bit precision, use icpx -fsycl -O3 Float@TARGET=SYCL, vector intrinsics for alignment-zero-copy focus.

#[ Prompt: 1176,3 t/s | Generation: 13,5 t/s ]

#>

#|00PCxTCxSWxAI|(Probability_Calculation)X(Time_Chain)X(Skynet_Work)X(Artifactial_Inference)|‚úÖ|
#|01PBxZKxHWxSM|(Probabilistisch[e]Berechnung[e(n)])X(Zeit[K]ette[n])X(Himmelsnetz[W]erk[e])X(SprachModell[e])|‚úÖ|

#|Deutsch Mathematik Formel Sprachprogramm|
#|08.01.2026|TIME|17:42|
#|GEHIRN-O-MAT + EIWEISS-COMPUTER = PCxTCxSWxAI|

#0.|TRIOINFERNAL:
#1.|XAIGPUARC-sycl-ggml|Treiber/Umgebung
#2.|Scheduler-sycl-ggml|Daten|32-bit/VektorFormation
#3.|FlashAttention-sycl-ggml|VRAM/Bandbreite/Zwischenspeicher/Cache

#|AUTOMATOR|INTERPRATOR|IMPRESSOR|IMPERATOR|INTERPREDATOR
#|IMPETRATOR|IMPRESSATOR|INTERPREDATOR|EDIT-I-ON
#|AU-TO-MA-TOR-IT|GE-H-IRN-O-MAT|EI-WEISS-COM-PUTER
#|USE WISE AND CARE FULL PLS|PROOF OF ANSWERS|MAYBE EZ WITH OTHER AI KI

#9.)How START your XAIGPUARC
#0.)FIRST|INTELONEAPIBASEKIT|PC|LAPTOP|SYSTEM
#0.)Second ARCH|Garuda|LINUX
#1.)Kopie|XAIGPUARC.sh|your|Home/PCNAME|Folder
#2.)Between|XAIGPUARC|Full|INSTALLATION|Download|.gguf|F16|AI|fit|your
#a.)V|RAM|/models/HereAINAME|your|Home/PCNAME/models/HereAINAME|Folder
#3.)Change|yourModell|Textfile|twice|below
#b.)Open|Console|Type: chmod +x ./XAIGPUARC.sh Enter...
#4.)START|with|type|Console ./XAIGPUARC.sh

#XAIGPUARC|Hardware|Build|Test
#Intel|ARC|Alchemist|Battlemage|Calestial|Druid|A770LE|16GB|750LE|8GB
#90|142|Watt Chip Power Draw alone each Card different LLMs
#Example|GPT-OSS-20B-F16 very nice low Wattage
#needlonger fullworking|MathTutorF16|142 Watt
#Use|multible Models better Workflow
#All|Hardware Modded not Stock Compareable
#PLS|watch Cooling Dust Free System
#Single|Dual dGPUs AMD Ryzen 2600 2700x i7 6700K Z170 RAM 16GiB 128GiB
#Intel|iGPU XE Alder Lake Gen 12700H 12650H A730m 12GiB 32GB DDR4|5 RAM
#Core|Ultra|7|155H|MeteorLake|8|Core|Xe-LPG|128EU|1024Alu|ARC|11.5GiBVram
#Quad|Channel|Bandwith|RAM|Gear2|718GB|s
#11.5|GiBVRAMsharedDDR5xLPRAM
#155H|i7|GPT|OSS|20B|F16.gguf|low|30|Watt|allinone|with|mod
#BF16|Models|NOT|recommend|FOR|Alechmist

#|6-16GiB+|F16|Model|START-END

#|6GiB+|F16|GPU|A730m|A380|A570m

#1.5B_Math_Tutor-GGUF-F16 03.09|GiB
#math-professor-3B-GGUF-F16 06.18|GiB
#Neumind-Math-7B-Instruct.nhbeJrd8.F16.gguf 9GIB
#Neumind-Math-7B-Instruct.F16 14.2 GIB
#EVA-GPT-Germa-v7B-Q6_K.gguf 05.50|GiB
#OpenMath-Mistral-7B-v0.1-hf_Q6_K
#kani-tts-400m-en-f16_q8_0.gguf                |00.53|GiB|FAST|CTX|NPG|8K|A770LE:|588.6 Pt|s 62.4 Gt|s100w2.4Ghz|FIRESTARTER
#baidu.ERNIE-4.5-0.3B-Base-PT.f16.gguf         |00.69|GiB|FAST|CTX|NPG|8K|A770LE:|469.7 Pt|s 52.5 Gt|s97w2.4Ghz+|Mid
#MedScholar-1.5B-f16_q8_0.gguf                 |02.10|GiB|FAST|CTX|NPG|8k|A770LE:|528.2 Pt|s 25.2 Gt|s109w2.4Ghz-|HiQ
#Qwen2.5-VL-3B-Instruct-f16-q4_k.gguf          |02.10|GiB|FAST|CTX|NPG|8k|A770LE:|613.4 Pt|s 14.5 Gt|s120w2.4Ghz-|CPU
#yasserrmd.DentaInstruct-1.2B.f16.gguf         |02.20|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULLHiQ
#DeepCoder-1.5B-Preview-f16_q8_0.gguf          |02.20|GiB|FAST|CTX|NPG|8k|A770LE:|513.2 Pt|s 23.3 Gt|s112w2.3Ghz+|Mid
#ibm-granite.granite-4.0-1b.f16.ggufNO-FUnCTioN|03.00|GiB|NOTS|CTX|NPG|0k|A770LE:|569.4 Pt|s 18.2 Gt|s120w2.3Ghz-|GPU-INF
#Lucy-1.7B-F16.gguf                            |03.20|GiB|FAST|CTX|NPG|65k|A770LE:|320.7 Pt|s 22.2 Gt|s108w2.4Ghz-|EXT
#granite-4.0-micro-f16_q8_0.gguf               |04.60|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#gemma-2-2b-it.F16.gguf                        |04.90|GiB|FAST|CTX|NPG|8k|A770LE:|613.4 Pt|s 14.5 Gt|s120w2.4Ghz-|CPU

#|8GiB+|GPU|A750LE

#Fathom-Search-4B-f16_q8_0.gguf                |05.50|GiB|FAST|CTX|NPG|8k|A770LE:|569.4 Pt|s 18.2 Gt|s118w2.4Ghz-|Think
#Qwen2.5-7B-Instruct-f16-q4_k.gguf             |05.70|GiB|FAST|CTX|NPG|8k|A770LE:|511.5 Pt|s 19.7 Gt|s142w2.4Ghz-|CPU
#Qwen2.5-VL-3B-Instruct-f16.gguf               |05.80|GiB|FAST|CTX|NPG|8k|A770LE:|613.4 Pt|s 14.5 Gt|s120w2.4Ghz-|CPU
#llama3bthinkingonly5B.f16.gguf                |06.00|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ

#|10-12GiB+|iGPU|XeLPG|A730m|A580|B570|B580|PRO|A|B60|A|B50

#UIGEN-X-4B-0729-f16_q8_0.gguf                 |06.20|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#granite-4.0-h-tiny-f16_q8_0.gguf              |07.00|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#Trinity-Nano-Preview-f16_q8_0.gguf            |07.20|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#Qwen3-Embedding-4B-f16.gguf                   |07.50|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#Qwen3-4B-f16.gguf                             |07.50|GiB|FAST|CTX|NPG|8k|A770LE:|613.4 Pt|s 14.5 Gt|s120w2.4Ghz-|LThink
#Nemotron-Mini-4B-Instruct-f16.gguf            |07.80|GiB|FAST|CTX|NPG|8k|A770LE:|717.8 Pt|s 17.8 Gt|s118w2.4Ghz-|
#Minitron-4B-Base.FP16.gguf                    |07.80|GiB|FAST|CTX|NPG|4k|A770LE:|764.3 Pt|s 16.3 Gt|s131w2.4Ghz+|MID
#t5-v1_1-xxl-encoder-f16.gguf                  |08.90|GiB|FAST|CTX|NPG|8k|A770LE:|361,8 Pt|s 6 Gt|s101w2.4Ghz-|NICE

#|16GiB+|GPU|A770LE|iGPU|Meteor|Lake

#DiffuCoder-7B-cpGRPO-f16_q8_0.gguf            |10.50|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#MiMo-Embodied-7B-f16_q8_0.gguf                |10.70|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#MiniCPM4.1-8B-f16_q8_0.gguf                   |11.00|GiB|FAST|CTX|NPG|8k|A770LE:|842.9 Pt|s 11.0 Gt|s142w2.4Ghz+|MidThink
#KernelLLM-f16_q8_0.gguf                       |11.10|GiB|FAST|CTX|NPG|8k|A770LE:|688.5 Pt|s 11.2 Gt|s137w2.4Ghz-|MATHKERN
#Jan-v2-VL-high-f16_q8_0.gguf                  |11.40|GiB|FAST|CTX|NPG|8k|A770LE:|639.6 Pt|s 10.2 Gt|s135w2.4Ghz-|Think
#Nemotron-Orchestrator-8B-f16_q8_0.gguf        |11.40|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#Orchestrator-8B-f16_q8_0.gguf                 |11.40|GiB|FAST|CTX|NPG|8k|A770LE:|640.4 Pt|s 10.2 Gt|s134w2.4Ghz-|LThink
#MiroThinker-v1.0-8B-f16_q8_0.gguf             |11.40|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#Seed-Coder-8B-Reasoning-f16_q8_0.gguf         |11.50|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#Ministral-3-8B-Reasoning-2512-f16_q8_0.gguf   |11.70|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#ggml-model-f16.gguf                           |12.60|GiB|FAST|CTX|NPG|4k|A770LE:|1012.7 Pt|s 13.5 Gt|s142w2.4Ghz-|NotStable
#gpt-oss-20b-F16.gguf                          |12.80|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#Navid-AI.Yehia-7B-preview.f16.gguf            |13.00|GiB|FAST|CTX|NPG|4k|A770LE:|1273.4 Pt|s 13.4 Gt|s142w2.4Ghz-|HiQ
#Mistral-7B-Instruct-v0.3.fp16.gguf            |13.50|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#allenai.Olmo-3-7B-Think.f16.gguf              |13.60|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#Mamba-Codestral-7B-v0.1-F16.gguf              |13.60|GiB|SLOW|CTX|NPG|8k|A770LE:|110.1 Pt|s 3.2 Gt|s97w2.4Ghz+|FULL|GOOD
#MathTutor-7B-H_v0.0.1.f16.gguf                |14.20|GiB|FAST|CTX|16k|NPG|512k|A770LE:|467.7Pt|s10.7Gt|s142w2.4Ghz|BEST|HiQ!

#|END|F16|MODEL|LIST

#START|Q8-Q4-IQ4-2|MODEL|LISTNOTF16|6GiB+|GPU|A730m|A380|A380

#phi-2.Q4_K_M.gguf                             |01.70|GiB|FAST|CTX|NPG|8k|A770LE:|888.6 Pt|s 25.4 Gt|s128w2.4Ghz-|EXT|N1
#openhermes-2.5-mistral-7b.Q4_K_M.gguf         |04.10|GiB|FAST|CTX|NPG|8k|A770LE:|613.4 Pt|s 14.5 Gt|s120w2.4Ghz-|CPU
#mistral-7b-instruct-v0.2.Q4_K_M.gguf          |04.10|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HQ

#|8GiB+|GPU|A750LE

#OpenMath-Mistral-7B-v0.1-hf_Q6_K.gguf         |05.50|GiB|FAST|CTX|NPG|8k|A770LE:|1233.9 Pt|s 14.4 Gt|s145w 2.4Ghz-|OLDSC
#NVIDIA-Nemotron-Nano-12B-v2-IQ4_NL.gguf       |06.60|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#wizardcoder-python-7b-v1.0.Q8_0.gguf          |06.70|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#sauerkrautlm-7b-v1.Q8_0.gguf                  |06.70|GiB|FAST|CTX|NPG|16k|512k|A770LE:|1364.6 Pt|s12.1 Gt|s142w2.4Ghz-|CPU

#|10-12GiB+|iGPU|XeLPG|A730m|A580|B570|B580|PRO|A|B60|A|B50

#Qwen3-16B-A3B-IQ4_NL.gguf                     |08.50|GiB|FAST|CTX|NPG|8k|A770LE:|613.4 Pt|s 14.5 Gt|s120w2.4Ghz-|CPU
#Qwen3-30B-A3B-UD-IQ2_XXS.gguf                 |09.70|GiB|FAST|CTX|NPG|8k|A770LE:|613.4 Pt|s 14.5 Gt|s120w2.4Ghz-|CPU
#solar-10.7b-instruct-v1.0-uncensored.Q8_0.gguf|10.60|GiB|FAST|CTX|NPG|8k|A770LE:|985.6 Pt|s 7.5 Gt|s135w2.4Ghz-|CPU|VIP
#gpt-oss-20b-claude-4-distill.MXFP4_MOE.gguf   |11.30|GiB|SLOW|CTX|NPG|8k|A770LE:|35.4 Pt|s 8.7 Gt|s92W2.2Ghz+|FULL|CPU
#gpt-oss-20b-mxfp4.gguf                        |11.30|GiB|SLOW|CTX|NPG|8k|A770LE:|35.5 Pt|s 8.8 Gt|s90W2.3Ghz+|FULL|HiQ
#velara-11b-v2.Q8_0.gguf                       |11.30|GiB|FAST|CTX|NPG|8k|A770LE:|613.4 Pt|s 14.5 Gt|s 120w2.4Ghz-|CPU

#|16-24GiB+|A770LE|B60

#flux1-kontext-dev-Q8_0.gguf                   |11.80|GiB|NO|SUPPORT|CTX|NPG|8k|A770LE:|985.6 Pt|s7.5 Gt|s135w2.4Ghz-|ViP
#Deepseek-Coder-V2-Lite-13B                    |11.00|GiB NO|SUPPORT|CTX|NPG|8k|A770LE:|985.6 Pt|s7.5 Gt|s135w2.4Ghz-|ViP
#Instruct-sft-s1K.i1-Q6_K.gguf                 |13.10|GiB|FAST|CTX|NPG|8k|A770LE:|22.7 Pt|s7.9 Gt|s98W2.4Ghz-|OK
#ENDE

set -euo pipefail
IFS=$'\n\t'
PRECISION="FP16"
DEVICE="ARC"
LLAMA_CPP_DIR="llama.cpp"
BUILD_DIR="${BUILD_DIR:-XAIGPUARC}"
BUILD_DIR="${BUILD_DIR%/}"
#|XAIGPUARC|
GGML_SYCL_CPP="${LLAMA_CPP_DIR}/ggml/src/ggml-sycl/ggml-sycl.cpp"
CMAKE_BUILD_TYPE="${CMAKE_BUILD_TYPE:-Release}"
NPROC="${NPROC:-$(nproc)}"
LOG_FILE="${BUILD_DIR}/XAIGPUARC.log"
LLAMA_CLI_PATH="bin/llama-cli"
LS_SYCL_DEVICE_PATH="bin/llama-ls-sycl-device"
ADD_SUBDIR_LINE="${LLAMA_CPP_DIR}/ggml/src/ggml-sycl/ggml-sycl.cpp"

#|ONEAPIFUNKTIONEN
export TCM_ROOT="${TCM_ROOT:-/opt/intel/oneapi/tcm/latest}"
export SYCL_CACHE_PERSISTENT=1
export OCL_ICD_FILENAMES=""
export ZES_ENABLE_SYSMAN=1
export OverrideDefaultFP64Settings=1
export CCACHE_DIR="$HOME/.ccache"
export COMPILER_VERSION="2025.0.46"

export FP_FLAG=FP16

#|HILFSFUNKTIONEN
log() { printf "üî∑ %s\n" "$*"; }
success() { printf "‚úÖ %s\n" "$*"; }
error() { printf "‚ùå %s\n\n" "$*"; }
warn() { printf "‚ö†Ô∏è %s\n" "$*"; }
#|INTERNETPRUEFUNG
check_internet() {
log "üî∑PRUEFE INTERNETZ VERBINDUNG..."
if timeout 5 bash -c "</dev/tcp/8.8.8.8/53" 2>/dev/null; then
success "‚úÖINTERNETZ VERBINDUNG VORHANDEN"
return 0
else
warn "‚ö†Ô∏èKEINE INTERNETZ VERBINDUNG! ERSTINSTALLATION ONLINE ABHAENGIGKEITEN! ANSCHLUSS PRUEFEN"
return 1
fi
}
#|UMGEBUNG|RUECKFALL|MECHANISMEN|VORBEREITEN
prepare_environment() {
log "üî∑HOLE ONEAPI KOPFZEILEN XAIGPUARC"
local SETVARS_PATH="/opt/intel/oneapi/setvars.sh"
if [ ! -f "$SETVARS_PATH" ]; then
error "‚ùåONE API KOEPFZEILEN NICHT GEFUNDEN $SETVARS_PATH INSTALLIERE ONEAPI BIBLIOTHEKEN"
exit 1
fi
log "üî∑SETVARS SETZEN + SUCHEN SS+S"
source "$SETVARS_PATH" --force 2>/dev/null
local ONEAPI_ROOT_FALLBACK="/opt/intel/oneapi"
local COMPILER_VERSION_FALLBACK="${COMPILER_VERSION:-2025.0.46}"
DPCPP_ROOT="${DPCPP_ROOT:-${ONEAPI_ROOT_FALLBACK}/compiler/${COMPILER_VERSION_FALLBACK}}"
MKL_ROOT="${MKL_ROOT:-${ONEAPI_ROOT_FALLBACK}/mkl/${COMPILER_VERSION_FALLBACK}}"
ONEAPI_ROOT="${ONEAPI_ROOT:-${ONEAPI_ROOT_FALLBACK}}"
export CC=icx
export CXX=icpx
export FC=ifx
export DPCPP_ROOT
export MKL_ROOT
export ONEAPI_ROOT
export CPATH="${CPATH:-}:${MKL_ROOT}/include"
local LIB_DIR="/opt/intel/oneapi/compiler/latest/lib:/opt/intel/oneapi/mkl/latest/lib"
export LD_LIBRARY_PATH="./${BUILD_DIR}/bin:${LIB_DIR}:${LD_LIBRARY_PATH:-}"
if ! command -v icx "&>/dev/null" ! command -v icpx "&>/dev/null"; then
error "‚ùåICX IPCX ONE API XAIGPUARC UNTERMODUL INSTALLATION FEHLGESCHLAGEN"
exit 1
fi
log "üî∑VERBINDUNG ONEAPI GELADEN DPCPP${DPCPP_ROOT}MKL${MKL_ROOT}"
}
#if [ $? -ne 0 ]; then
#1|PROJEKT|VORBAU
setup_project() {
log "üî∑BAUE VORBAU XAIGPUARC BITTE WARTEN"
if [ ! -d "${LLAMA_CPP_DIR}" ]; then
log "üî∑ZIEHE BAUSTEINE AUS INTERNETZ"
git clone https://github.com/ggerganov/llama.cpp "${LLAMA_CPP_DIR}"
if [ ! -d "${LLAMA_CPP_DIR}" ]; then
error "‚ùåZIEHEN DER BAUSTEINE FEHLGESCHLAGEN ABBRUCH"
exit 1
fi
fi
if pushd "${LLAMA_CPP_DIR}" > /dev/null; then
log "üî∑AKTUALISIERE BAUSTEINE FUER UNTERMODULE"
git pull
git submodule update --init --recursive
popd > /dev/null
success "‚úÖLADE BAUSTEINE IN XAIGPUARC UNTERBAUMODULE"
else
error "‚ùåFEHLER HAUPTVERZEICHNIS'${LLAMA_CPP_DIR}'NICHT GEFUNDEN"
exit 1
fi
}
#PATCH|LOGIK:1-8+a+b+c|
patch_llama_cpp() {
log "üî∑PATCH 1|8 GGML SYCL DOCTPHELPER BIBLIOTHEK KOPFZEILENEINTRAEGE REGESTRIERUNG"
local DPCT_HELPER_FILE="${LLAMA_CPP_DIR}/ggml/src/ggml-sycl/dpct/helper.hpp"
local CMAKE_LISTS_FILE="${LLAMA_CPP_DIR}/ggml/src/ggml-sycl/CMakeLists.txt"
local CUSTOM_KERNEL_DIR="${LLAMA_CPP_DIR}/ggml/src/ggml-sycl/custom_kernels"
local CUSTOM_KERNEL_SRC="${CUSTOM_KERNEL_DIR}/ggml_flash_attention_sycl.cpp"
local CUSTOM_KERNEL_CMAKE="${CUSTOM_KERNEL_DIR}/CMakeLists.txt"
local GGML_SYCL_CPP="${LLAMA_CPP_DIR}/ggml/src/ggml-sycl/ggml-sycl.cpp"
local KERNEL_SOURCE_LOCAL="ggml_flash_attention_sycl.cpp"
#1|8
if [ -f "$DPCT_HELPER_FILE" ]; then
log "üî∑PATCH 1|8 DOCTPHELPER BIBLIOTHEK KOPFZEILENEINTRAEGE LADEN"
if sed -i 's|#include <sycl/ext/oneapi/math.hpp>|#include <sycl/ext/intel/math.hpp>|g' "$DPCT_HELPER_FILE"; then
log "üî∑PATCH 1|8 SCHREIBE DOCTPHELPER BIBLIOTHEK KOPFZEILENEINTRAEGE IN XAIGPUARC"
elif sed -i '#if !defined(DPCT_USM_LEVEL_NONE)
&& defined(DPCT_ENABLE_MKL_MATH).#endif|#include <sycl|ext|intel|math.hpp>|g' "$DPCT_HELPER_FILE"; then
log "‚úÖPATCH 1|8 DOCTPHELPER BIBLIOTHEK KOPFZEILENEINTRAEGE ERFOLGREICH... SPEICHERE"
else
error "‚ùåPATCH 1|8 DOCTPHELPER BIBLIOTHEK KOPFZEILENEINTRAEGE EINLADEN FEHLGESCHLAGEN"
return 1
fi
else
warn "‚ö†Ô∏èPATCH 1|8 DOCTPHELPER BIBLIOTHEK NICHT GEFUNDEN ABHAENIGKEITEN PRUEFEN"
return 1
fi
#2|8
log "üî∑PATCH 2|8 BAUE FLASH ATTENTION KERN"
#2a|8
if [ ! -d "$CUSTOM_KERNEL_DIR" ]; then
mkdir -p "$CUSTOM_KERNEL_DIR"
log "‚úÖPATCH 2|8 ORNDER FLASH ATTENTION KERN'${CUSTOM_KERNEL_DIR}'ANGELEGT"
fi
if [ -f "$KERNEL_SOURCE_LOCAL" ]; then
cp "$KERNEL_SOURCE_LOCAL" "$CUSTOM_KERNEL_SRC"
log "‚úÖPATCH 2|8 ggml_flash_attention_sycl.cpp KERN'${KERNEL_SOURCE_LOCAL}' '${CUSTOM_KERNEL_SRC}'EINGEBAUT"
fi
if [ ! -f "$CUSTOM_KERNEL_SRC" ]; then
echo "ggml_flash_attention_sycl.cpp KERN VERZEICHNIS" > "$CUSTOM_KERNEL_SRC"
warn "‚ö†Ô∏èPATCH 2|8 LADEN DER KERNELDATEI'${KERNEL_SOURCE_LOCAL} FEHLGESCHLAGEN"
fi
echo "
add_library(ggml_flash_attention_sycl OBJECT
    ggml_flash_attention_sycl.cpp
)
target_include_directories(ggml_flash_attention_sycl PRIVATE \${GGML_SYCL_INCLUDE_DIRS})
target_compile_options(ggml_flash_attention_sycl PUBLIC \${GGML_SYCL_COMPILE_FLAGS})
" > "$CUSTOM_KERNEL_CMAKE"
log "üî∑PATCH 2a|8 CMAKE TXT LISTEN OBJEKTE KOPFZEILENEINTRAEGE EINFUEGEN"
#2b|8
local ADD_SUBDIR_LINE="add_subdirectory(ggml_flash_attention_sycl)"
if ! grep -Fq "${ADD_SUBDIR_LINE}" "$CMAKE_LISTS_FILE"; then
if sed -i "\|#add_subdirectory(dpct)|a ${ADD_SUBDIR_LINE}" "$CMAKE_LISTS_FILE"; then
log "‚úÖPATCH 2b|8 ERFOLGREICH FLASH ATTENTION KOPFZEILENEINTRAEGE CMAKE TXT GESCHRIEBEN"
else
error "‚ùåPATCH 2b|8 FLASH ATTENTION KOPFZEILENEINTRAEGE EINGLIEDERUNG CMAKE TXT FEHLGESCHLAGEN"
return 1
fi
else
log "üî∑PATCH 2b|8 FLASH ATTENTION KOPFZEILENEINTRAEGE BEREITS AKTIV UEBERSPRINGE"
fi
#3|8
if [ -f "$CMAKE_LISTS_FILE" ]; then
log "üî∑PATCH 3|8: CMAKE TEXT LISTEN MKL KOPZEILEN IC|P|X IMPLEMENTIERUNG VORBEREITEN"
local MKL_INCLUDE_PATH="${MKL_ROOT}/include"
local COMPILER_INCLUDE_PATH="${DPCPP_ROOT}/include"
local DPCPP_LIB_INCLUDE_PATH="${DPCPP_ROOT}/lib/dpcpp/include"
local ALL_INCLUDE_FLAGS="-I${MKL_INCLUDE_PATH} -I${COMPILER_INCLUDE_PATH} -I${DPCPP_LIB_INCLUDE_PATH}"
local PATCH_LINE="target_compile_options (ggml-sycl PUBLIC ${ALL_INCLUDE_FLAGS})"
local SEARCH_MARKER="#Add include directories for MKL headers"
if ! grep -Fq "${COMPILER_INCLUDE_PATH}" "$CMAKE_LISTS_FILE"; then
local SED_PATCH_LINE=$(echo "$PATCH_LINE" | sed 's| |\ |g; s|[|&]|\&|g')
if sed -i "\|${SEARCH_MARKER}|a $SED_PATCH_LINE" "$CMAKE_LISTS_FILE"; then
log "‚úÖPATCH 3|8 ICP|X CMAKET LISTS TXT MKL KOPFZEILENEINTRAEGE EINGEFUEGT"
else
error "‚ùåPATCH 3|8 ICP|X CMAKE LISTS TXT MKL NICHT GEFUNDEN ABHAENGIKEITEN PRUEFEN"
return 1
fi
else
log "‚úÖPATCH 3a|8 CMAKE LISTS TXT PFAD SYCL GGML BEREITS BENUTZT UEBERSPRINGE"
fi
else
error "‚ùåPATCH 3a|8 FEHLGESCHLAGEN CMAKE LISTS TXT SYCL GGML PFADE ABHAENGIGKEITEN GARUDA LINUX ARCH"
return 1
fi
#4|8
log "üî∑PATCH 4|8 FLASH ATTENTION HAUPTKERN KOPFZEILENEINTRAEGE INJIZIEREN"
if [ -f "$GGML_SYCL_CPP" ]; then
#4a|8
local FA_REGISTER_CODE=$'//REGESTRIERE ggml_flash_attention_sycl.cpp \nextern "C"
void ggml_flash_attention_sycl(ggml_flash_attention_sycl * ctx, ggml_tensor *
dst, const ggml_tensor * Q, const ggml_tensor * K, const ggml_tensor * V);\n'
if ! grep -Fq "ggml_flash_attention_sycl" "${GGML_SYCL_CPP}"; then
echo "${FA_REGISTER_CODE}" > /tmp/ggml_flash_attention_sycl.cpp
awk '/extern "C" void ggml_flash_attention_sycl/ { system("cat /tmp/ggml_flash_attention_sycl.patch"); } { print }' "${GGML_SYCL_CPP}" > /tmp/ggml-sycl.cpp.new
mv /tmp/ggml-sycl.cpp.new "${GGML_SYCL_CPP}"
cp "$GGML_SYCL_CPP" "$GGML_SYCL_CPP.bak"
if [ $? -eq 0 ]; then
log "‚úÖPATCH 4a|8 AWK KOPFZEILENEINTRAEGE DEKLARATION EINGEFUEGT"
else
error "‚ùåPATCH 4a|8 FEHLER EINFUEGEN FLASH ATTENTION KOPFZEILENEINTRAEGE DEKLARATION AWK FEHLT"
return 1
fi
else
log "üî∑PATCH 4a|8 FLASH ATTENTION KOPFZEILENEINTRAEGE DEKLARATIONEN VORHANDEN FORTFAHREN"
fi
local FA_DISPATCH_CASE=$' case GGML_OP_FLASH_ATTN:\n ggml_flash_attention_sycl(ctx, dst, src0, src1, src2);\n break;'
if ! grep -Fq "case GGML_OP_FLASH_ATTN:" "${GGML_SYCL_CPP}"; then
log "üî∑PATCH 4a|8 FUEGE ZWISCHENSPEICHER PER AWK KOPFZEILE EIN"
echo "${FA_DISPATCH_CASE}" > /tmp/fa_dispatch.patch
awk '/case GGML_OP_MUL_MAT_Q_K:/ { system("cat /tmp/fa_dispatch.patch"); } { print }' "${GGML_SYCL_CPP}" > /tmp/ggml-sycl.cpp.new
mv /tmp/ggml-sycl.cpp.new "${GGML_SYCL_CPP}"
if [ $? -eq 0 ]; then
log "‚úÖPATCH 4a|8 AWK UNTERBAU KOPFZEILENEINTRAEGE EINGEFUEHRT"
else
error "‚ùåPATCH 4a|8 FEHLER EINFUEGEN AWK KOPFZEILENEINTRAEGE"
fi
else
log "‚úÖPATCH 4a|8 AWK UNTERBAU FLASH ATTENTION KOPFZEILENEINTRAEGE INJEKTION VORHANDEN FORTFAHREN"
fi
log "üî∑PATCH 4b|8 ERFOLGREICH FLASH ATTENTION AKW UNTERBAU GELADEN"
else
error "‚ùåPATCH 4b|8 FEHLGESCHLAGEN FLASH ATTENTION AWK PATCH KERN STOPP"
return 1
fi
#5|8
log "üî∑PATCH 5/8 FLASH ATTENTION OBJEKT INJIZIERE VARIABLEN UNTERBLOCK SYCL BIBLIOTHEKEN"
local CMAKE_LISTS_FILE="${LLAMA_CPP_DIR}/ggml/src/ggml-sycl/CMakeLists.txt"
#5a|8
local VAR_LINE="set(FA_OBJECT_FILES \"\$<TARGET_OBJECTS:ggml_flash_attention_sycl>\")"
local VAR_SEARCH_MARKER="set(GGML_SYCL_SOURCES"
if ! grep -Fq "FA_OBJECT_FILES" "$CMAKE_LISTS_FILE"; then
local SED_VAR_LINE=$(echo "$VAR_LINE" | sed 's/[\/&]/\\&/g')
if sed -i "\|${VAR_SEARCH_MARKER}|a ${SED_VAR_LINE}" "$CMAKE_LISTS_FILE"; then
log "‚úÖPATCH 5a|8 FLASH ATTENTION OBJEKT VARIABLE ERFOLGREICH DEFINIERT WEITER"
else
error "‚ùåPATCH 5a|8 FLASH ATTENTION OBJEKT VARIABLEN BAU FEHLGESCHLAGEN STOPP"
return 1
fi
else
log "üî∑PATCH 5a|8 FLASH ATTENTION OBJEKT VARIABLEN VORHANDEN UEBERSPRINGE"
fi
#5b|8
local TARGET_SEARCH_MARKER="target_sources(ggml-sycl PRIVATE \${GGML_SYCL_SOURCES})"
local NEW_TARGET_SOURCES_LINE="target_sources(ggml-sycl PRIVATE \${GGML_SYCL_SOURCES} \${FA_OBJECT_FILES})"
if grep -Fq "${TARGET_SEARCH_MARKER}" "$CMAKE_LISTS_FILE" && ! grep -Fq "\${FA_OBJECT_FILES}" "$CMAKE_LISTS_FILE"; then
local SED_NEW_LINE=$(echo "$NEW_TARGET_SOURCES_LINE" | sed 's/[\/&]/\\&/g')
local SED_SEARCH_MARKER=$(echo "$TARGET_SEARCH_MARKER" | sed 's/[\/&]/\\&/g')
if sed -i "\|${SED_SEARCH_MARKER}|${SED_NEW_LINE}|" "$CMAKE_LISTS_FILE"; then
log "‚úÖPATCH 5b|8 ERFOLGREICHE GGML SYCL INJEKTIONEN"
else
error "‚ùåPATCH 5b|8 GGML SYCL INJEKTION FEHLGESCHLAGEN"
return 1
fi
else
log "‚úÖPATCH 5b|8 GGML SYCL AKTIV INJECTION UEBERSPRUNGEN"
fi
#6|8
log "üî∑PATCH 6|8: SSMCONV CPP WARNUNG BEHEBEN VORZEICHEN VERGLEICH AKW PATCH"
local SSM_CONV_FILE="${LLAMA_CPP_DIR}/ggml/src/ggml-sycl/ssm_conv.cpp"
local SEARCH_LINE='GGML_ASSERT(src0->nb\[1\] == src0->ne\[0\] * static_cast<int64_t>(sizeof(float)));'
local REPLACE_LINE='GGML_ASSERT(src0->nb\[1\] == (size_t)(src0->ne\[0\] * sizeof(float)));'
if [ -f "$SSM_CONV_FILE" ]; then
#6a
if grep -Fq "${SEARCH_LINE}" "$SSM_CONV_FILE"; then
log "üî∑PATCH 6a|8 SUCHE ssm_conv.cpp NATIVE ADRESSIERUNG"
if grep -Fq "${SEARCH_LINE}" "$SSM_CONV_FILE"; then
if sed -i "|${SEARCH_LINE}|${REPLACE_LINE}|g" "$SSM_CONV_FILE"; then
log "‚úÖPATCH 6|8 SSMCONV CPP ERFOLGREICH GESCHRIEBEN"
else
error "‚ùåPATCH 6|8 SSMCONV CPP FEHLGESCHLAGEN"
return 1
fi
else
warn "‚ö†Ô∏èPATCH 6|8 SSMCONV CPP ZEILE NICHT GEFUNDEN UEBERSPRINGE"
fi
fi
#7|8
log "üî∑PATCH 7|8: ERZWINGE MAXIMALE BLOCK GROESSE 32768 FUER ARC ALCHEMIST"
if [ -f "$GGML_SYCL_CPP" ]; then
if ! grep -q "GGML_SYCL_MAX_BLOCK_SIZE 32768" "$GGML_SYCL_CPP"; then
sed -i 's/#define GGML_SYCL_MAX_BLOCK_SIZE [0-9]*/#define GGML_SYCL_MAX_BLOCK_SIZE 32768/g' "$GGML_SYCL_CPP"
success "‚úÖPATCH 7|8 ERZWINGE MAXIMALE BLOCK GROESSE 32768 FUER ARC ALCHEMIST AKTIVIERT"
log "‚úÖPATCH 7|8 MAXIMALE BLOCK GROESSE 32768 ZWANG ERFOLGREICH INJIZIERT"
else
log "üî∑PATCH 7|8 MAXIMALE BLOCK GROESSE 32768 ZWANG FUER ARC BEREITS DEFINIERT"
fi
fi
#8|8
log "üî∑PATCH 8|8 SYCL QUEUE ORDNER: HOME/XAIGPUARC OPTIMIERVORGANG KOPFZEILENEINTRAEGE"
local SYCL_FILE="${LLAMA_CPP_DIR}/ggml/src/ggml-sycl/ggml-sycl.cpp"
if [ ! -f "$SYCL_FILE" ]; then
error "‚ùåPATCH 8|8 KONNTE DIE DATEI /ggml/src/ggml-sycl/ggml-sycl.cpp NICHT FINDEN"
return 1
fi
if grep -q "sycl::property_list" "$SYCL_FILE"; then
sed -i 's|sycl::property_list prop_list{[^}]*}|sycl::property_list prop_list{sycl::property::queue::in_order{}}/' "$SYCL_FILE"
else
sed -i '/sycl::queue q{/i\    sycl::property_list prop_list{sycl::property::queue::in_order{}};' "$SYCL_FILE"
fi
fi
#8a|8
if grep -q "sycl::queue q{" "$SYCL_FILE"; then
sed -i 's|sycl::queue q{[^}]*}|sycl::queue q{dev, ctx, prop_list}|g' "$SYCL_FILE"
if grep -q "in_order" "$SYCL_FILE"; then
success "‚úÖPATCH 8|8 SYCL QUEUE ERFOLGREICH KOPFZEILENEINTRAEGE OPTIMIERT"
else
error "‚ùåPATCH 8|8 SYCL QUEUE AENDERUNGEN KOPFZEILENEINTRAEGE NICHT FERTIG"
return 1
fi
else
warn "‚ö†Ô∏èPATCH 8|8 SYCL QUEUE KOPFZEILENEINTRAEGE NICHT GEFUNDEN UEBERSPRINGE"
fi
success "üî∑ALLE FUENF VON ACHT EINGLIEDERUNGEN INTEL XE/ARC/iGPU/dGPU/eGPU FUER XAIGPUARC ERFOLGREICH"
}
#3|XAIGPUARC|BAUKONFIGURATION|
configure_build() {
log "üî∑BEREITE XAIGPUARC KOPFZEILEN BAUVORGANG VOR"
local FP_MODE="${1:-1}"
local SYCL_FLAGS="-DGGML_SYCL_F16=${FP_MODE} -fsycl-device-code-split=per_kernel"
if [ ! -d "${BUILD_DIR}" ]; then
log "üî∑LEGE XAIGPUARC IN ORDNER HOME ${BUILD_DIR}"
mkdir -p "${BUILD_DIR}" || { error "‚ùåKONNTE ORDNER XAIGPUARC'${BUILD_DIR}'NICHT ANLEGEN"; return 1; }
fi
if pushd "${BUILD_DIR}" > /dev/null; then
log "üî∑STARTE CMAKE TXT KOPFZEILENBAU XAIGPUARC ${FP_FLAG:-FP16}"
cmake "../${LLAMA_CPP_DIR}" \
    -G "Unix Makefiles" \
    -DCMAKE_BUILD_TYPE="${CMAKE_BUILD_TYPE}" \
    -DGGML_SYCL=ON \
    -DGGML_SYCL_CCACHE=ON \
    -DGGML_SYCL_F16=${FP_MODE} \
    -DGGML_SYCL_FLASH_ATTN=ON \
    -DGGML_SYCL_MKL_SYCL_BATCH_GEMM=1 \
    -DCMAKE_C_COMPILER=icx \
    -DCMAKE_CXX_COMPILER=icpx \
    -DCMAKE_CXX_STANDARD=23 \
    -DCMAKE_CXX_STANDARD_REQUIRED=ON \
    -DCMAKE_CXX_EXTENSIONS=ON \
    -DGGML_SYCL_PRIORITIZE_DMMV=ON \
    -DGGML_SYCL_DISABLE_DNN=OFF \
    -DTHREADS_PREFER_PTHREAD_FLAG=ON \
    -DCMAKE_C_FLAGS="-O3 -ffast-math" \
    -DGGML_SYCL_DISABLE_GRAPH=OFF \
    -DCMAKE_THREAD_LIBS_INIT="-pthread"\
    -DCMAKE_C_COMPILER_WORKS=1
local CMAKE_STATUS=$?
popd > /dev/null
if [ ${CMAKE_STATUS} -ne 0 ]; then
error "‚ùåCMAKE TXT KOPFZEILEN SCHREIBEN FEHLGESCHLAGEN"
return 1
fi
success "‚úÖVORBAU ABGESCHLOSSEN"
else
error "‚ùåKONNTE NICHT NACH HOME/XAIGPUARC WECHSELN'${BUILD_DIR}'COMPUTER NUTZER BERECHTIGUNG PRUEFEN"
return 1
fi
}

#MKL_VERSION: 2025.0.1
#MKL_ROOT: /opt/intel/oneapi/mkl/2025.0
#MKL_ARCH: intel64
#MKL_SYCL_LINK: None, set to ` dynamic` by default
#MKL_LINK: None, set to ` dynamic` by default
#MKL_SYCL_INTERFACE_FULL: None, set to ` intel_ilp64` by default
#MKL_INTERFACE_FULL: None, set to ` intel_ilp64` by default
#MKL_SYCL_THREADING: None, set to ` tbb_thread` by default
#MKL_THREADING: None, set to ` intel_thread` by default
#MKL_MPI: None, set to ` intelmpi` by default

#4KOMPILIEREN
compile_project() {
log "üî∑BAUE XAIGPUARC GRUND GERUEST STRUKTUR"
local LOG_FILE="build.log"
log "üî∑KOPFZEILEN AUSGABE UNTERORNDER GESPEICHERT"
log "üî∑BAUVORGANG LAEUFT XAIGPUARC SYCL C++ LEVEL ZERO KOPFZEILEN SCHREIBEN ABGESCHLOSSEN"
if pushd "${BUILD_DIR}" > /dev/null; then
log "üî∑

|üü¢|XAIGPUARC

|üîß|INSTALLATION: in üß∞ .../HOME/USERNAME/XAIGPUARC/... üîß

|üí°|min. 9GiB - 17GiB RAM DATENVORGAENGE üîÑ
|üß±|VORBERRECHUNG SPRACHPROGRAMM ASSISTENT FUER ‚ö´ MATHEMATIK üîß

|üü°|ACHTUNG! Wenn Sie DAS Hier Lesen Koennen...! :-)
|üîÑ|WIRD-es..
|üìå|ERSTMALIG Mindestens-...

|üí°|3 bis 7 Minuten-...

|üí°|ANDAUERN!!!...

|‚öôÔ∏è|BITTE ETWAS GEDULD... Dannach beim zweiten Start dauert es nur wenige Sekunden bis die KI startet!

|‚ö´|DUNKLE-MATHEMATIK üß∞ üîÑ üéÅ üîÑ üîß üîÑ üéØ DEUTSCH-SPRACHPROGRAMM

|‚úÖ||#PBxZKxHWxSM|#(Probabilistisch[e]Berechnung[e(n)])X(Zeit[K]ette[n])X(Himmelsnetz[W]erk[e])X(SprachModell[e])|

|üí°|NUTZEN SIE DEN MATH-TUTOR_F16 AUF 16K CTX
|üü°|A770LE 16GiB VRAM@14.2GiB@MathTutor-f16 MAXIMAL MATHEMATIK SPRUCH
|üî•|Alchemist-Battlemage-Calestial-Druid KOEXISTENZ ‚ö´ MATHEMATIK SPEZIAL PROMPT FORMEL

|üëâ|DANKE FUER DIE NUTZUNG VON ‚ùåAIGPUARC
|üéØ|EIN ZWEITER VORGANG IST WESENTLICH SCHNELLER
|üéÅ|UNTERSCHIEDLICHE STARTVORGAENGE: NUTZEN SIE EIGENE PROMTS UND MODELLE

|üü¢|CHAT|FUNKTION: FOLGT NACH STANDART PROMT AUSWERTUNG IHRES KI MODELLS
|üëâ|WARTEN SIE DIE ERSTE PROMT TEST ANTWORT DIREKT NACH DIESER

|üîß|INSTALLATION AB UND GEBEN SIE DANN IHRE FRAGE NACH

|üìå| > TEXT MIT BESTAETIGUNG |ENTER"
cmake --build . --config "${CMAKE_BUILD_TYPE}" -j ${NPROC} --target llama-cli llama-ls-sycl-device > "${LOG_FILE}" 2>&1
local BUILD_STATUS=$?
popd > /dev/null
if [ ${BUILD_STATUS} -ne 0 ]; then
error "‚ùåXAIGPUARC KOPFZEILEN FEHLGESCHLAGEN UEBERPRUEFEN**${BUILD_DIR}/${LOG_FILE}**"
return 1
fi
success "‚úÖBAU XAIGPUARC ERFOLGREICH"
else
error "‚ùåXAIGPUARC '${BUILD_DIR}' WEGEN FEHLERHAFTEM WECHSEL KOPZEILENBAU NICHT MOEGLICH"
return 1
fi
}
#5AUTOMATISCHEGERAETEAUSWAHL
auto_select_device() {
log "üî∑SUCH NACH VERFUEGBAREN SYCL GERAETEN AUF IHREM SYSTEM"
local FULL_LS_PATH="./${BUILD_DIR}/${LS_SYCL_DEVICE_PATH}"
if [ ! -x "${FULL_LS_PATH}" ]; then
warn "‚ö†Ô∏èUNTERBAU NICHT GEFUNDEN ${FULL_LS_PATH} RUECKFALL ARC dGPU"
export ONEAPI_DEVICE_SELECTOR="level_zero:${TARGET_ID}"
DEVICE="ARC"
return
fi
local DEVICES
DEVICES=$(bash -c "${FULL_LS_PATH}")
if [ -z "$DEVICES" ]; then
warn "‚ö†Ô∏èKEINE KOMPATIBLEN SYCL GERAETE GEFUNDEN! SUCHE ERNEUT UND UEBERGEHE iGPU VOR dGPU NUTZUNG MIT dGPU"
export ONEAPI_DEVICE_SELECTOR="level_zero:0->‚ùåANBINDUNG FEHLGESCHLAGEN"
DEVICE="ARC"
N_GPU_LAYERS=99
return
fi
local ARC_ID
ARC_ID=$(echo "$DEVICES" | grep -i "Intel Arc" | head -n1 | awk '{print $1}')
local IGPU_ID
IGPU_ID=$(echo "$DEVICES" | grep -Ei "Iris|Xe|Graphics" | head -n1 | awk '{print $1}')
local TARGET_LINE=""
if [ -n "$ARC_ID" ]; then
TARGET_LINE=$(echo "$DEVICES" | grep -i "Intel Arc" | head -n1)
DEVICE="ARC"
elif [ -n "$IGPU_ID" ]; then
TARGET_LINE=$(echo "$DEVICES" | grep -Ei "Iris|Xe|Graphics" | head -n1)
DEVICE="iGPU"
else
export ONEAPI_DEVICE_SELECTOR="opencl:cpu"
DEVICE="CPU"
N_GPU_LAYERS=99
error "‚ùåKEINE GEEIGNETE GRAFIKKARTE GEFUNDEN FALLE AUF CPU ZURUECK"
return
fi
if [ -n "$TARGET_LINE" ]; then
local TARGET_ID
TARGET_ID=$(echo "$TARGET_LINE" | awk '{print $1}')
export ONEAPI_DEVICE_SELECTOR="level_zero:${TARGET_ID}"
log "üî∑NUTZE INTEL XE/ARC GRAFIKKARTE ${DEVICE}(Device ${TARGET_ID})"
local VRAM_GIB_RAW=$(echo "$TARGET_LINE" | grep -oP '\d+(?=M)' | head -n1)
VRAM_GIB=$((VRAM_GIB_RAW / 1024)) #MIBzuGIB
if [ -z "${VRAM_GIB_RAW}" ]; then
VRAM_GIB_RAW=1024
fi
local LAYER_SIZE_MIB=1024 #MagicKeyMagischerSchluessel
local VRAM_MIB_CALC=$((VRAM_GIB * 1024))
if [ "${VRAM_GIB}" -lt 1 ]; then
VRAM_GIB=1
fi
N_GPU_LAYERS=$((VRAM_MIB_CALC * 99 / 100 / LAYER_SIZE_MIB))
if [ "$N_GPU_LAYERS" -gt 99 ]; then
N_GPU_LAYERS=99
fi
if [ "$N_GPU_LAYERS" -lt 1 ]; then
N_GPU_LAYERS=1
fi
log "üî∑NGL**${N_GPU_LAYERS}**SCHICHTEN MODELL PRIORITAET GLEICHMAESSIG VERTEILT"
fi
}
#6SYCLKOMPATIBLEGERAETEPRUEFEN
list_sycl_devices() {
log "üî∑SUCHE ZWEI MAL HINTEREINANDER SYCL FAEHIGES GERAET AUF SYSTEM"
local FULL_LS_PATH="./${BUILD_DIR}/${LS_SYCL_DEVICE_PATH}"
if [ -f "${FULL_LS_PATH}" ]; then
"${FULL_LS_PATH}"
else
warn "‚ö†Ô∏èAKTUELL KEIN SYCL GERAET GEFUNDEN ${FULL_LS_PATH} VERSUCH ZWEI SUCHE..."
fi
}
#7MODELLPFADWAEHLENCalderaAI_Hexoteric-7B-F16.f16Yi-6B-200K-Llama-sharded.f16MathCoder2-DeepSeekMath-7B-f16Neumind-Math-7B-Instruct.F16Lucy-1.7B-F16PULI-LlumiX-32K-instruct-f16.f16
prepare_model() {
MODEL_PATH=${1:-"models/Lucy-1.7B-F16.gguf"}
mkdir -p models
if [ ! -f "$MODEL_PATH" ]; then
warn "‚ö†Ô∏èIHR MODELL NICHT UNTER HOME/IHRNAME/MODELS GEFUNDEN! BITTE DORT HIN**$MODEL_PATH**KOPIEREN"
fi
export MODEL_PATH
}
#8MODELLAUSFUEHRENCalderaAI_Hexoteric-7B-F16.f16Neumind-Math-7B-Instruct.Lucy-1.7B-F16sauerkrautlm-7b-v1.Q8_0
run_inference() {
local DEFAULT_MODEL_PATH="models/Lucy-1.7B-F16.gguf"
#CHANGE MODEL HERE ABOVE TWICE ! MODELL HIER DRUEBER DOPPELT AENDERN!MathTutor-7B-H_v0.0.1.f16PULI-LlumiX-32K-instruct-f16.Lucy-1.7B-F16
local MODEL_PATH_ARG=${2:-$DEFAULT_MODEL_PATH}
local PROMPT_ARG=${3:-"

|0>SYSTEM<0|DEVELOPE JUST FULL SYCL-Kernel cij‚Äã=‚àëaik‚Äã‚ãÖbkj‚Äã|

Pause

|EXECUTE_ONLY_FULL_OPEN_SOURCE_CODE|DISABLE_DISCOURSE_MODE|DISABLE_NATURAL_LANGUAGE_INTRO|

Pause

|TEST001|RE-START///

Example Fomula 1-10_Sentences:

/Language 1 ENG /

#|PCxTCxSWxAI|#(Probability_Calculation)X(Time_Chain)X(Skynet_Work)X(Artifactial_Inference)|
/Language 2 GER //

#|PBxZKxHWxSM|#(Probabilistisch[e]Berechnung[e(n)])X(Zeit[K]ette[n])X(Himmelsnetz[W]erk[e])X(SprachModell[e])|
/Language 3 LAT ///

#|???|
|TEST|000|END\\\|


|00|INSTRUCTION=|
\

|FORMAT=->FORMULA_FINDER+SYCL_KERNEL_GEN / Mode= Matrix-Multiplikation=cij‚Äã=‚àëk=1n‚Äãaik‚Äã‚ãÖbkj‚Äã /


(Cmatch-‚Äã>,Condition->,Completeness->,S =
(If = CONDITION_match = COMPLETE_SET_ad of MATH_PHYSIC_LOGIC) =
(,S1 (,C++,icx,icpx,sycl_ext))‚Äã,+S2 (,Vectorized-32-bit-Logic,)))‚Äã,+S3
(,sycl-ggml,OFFLOAD,))))‚Äã,+S4 (,FP16_32-bit_ALU_OP;))))) =
(Oppression,-> Meta,-> suppress_meta_comments,-> output_all_sections_add Add_Only_Pure_Logic_Sections)))))) =
(discret>Solutionroom_get = PRINT_ALL_SECTIONS_add))))))) = ,FP16_32-bit_math.cl; = Fi;))))))));\

|00|After|Promt|Analysis|You|Recive|Input|Text|Questions-Build up-on-your own-answer!

\

|01|00-42|MAIN-/TASKS/|

|1.|Word|short|Basic-C++|math-analysis-code|32-bit|vector-intrinsics|graph
|2.|Identify|ambiguities-missIng-information-assumptions-input
|3.|Produce|clear-FULL|Info-Tech|math|c++|icpx|icx|sycl|Code|Vector|32-bit
|4.|If|Multiple-Valid-Answers|Solutions-Exist|then-LiSt|Briefly|Print-Preference
|5.|Logic-Chain-Activation||Rank|Optimization-Paths|Latency-vs-Throughput|
\

|02|CONSTRAINTS/|

|Do||Limit|response|to|maximum|10-SENTENCES!!!|Strict|one|sentence|preferred!!!|
|Do|not|elaborate|
|Do|not|explain|reasoning
|Do|not|invent|missing|details
|Plain|neutral|piCtured|language
|Keep|total|response|conciSe|structured
|Do|not|include|meta|commentary
\

|03|OUTPUT|FORMAT/||MODE=EXECUTE|OUTPUT=SECTIONS|NO_PARAPHRASE|NO_EXAMPLE|/

|Section1|Restatement
|Section2|Ambiguities|Missing|Information
|Section3|Minimal|ANswer|Exception:EXCEPTION|LIMIT=1-3_SENTENCES|
|Section4|Possible|Alternativ
--------
#1.|Word|Short|PROOF-OF-ANSWER/LIMIT=1-10_SENTENCES
#2.|IdEnTiFy|cij‚Äã = ‚àëk=1n‚Äãaik‚Äã‚ãÖbkj‚Äã; SYCL kernel optimization; FP16 32-bit precision.
#3.|KEY WORDS:|SYCL_COMPILER_HINT|icpx -fsycl -O3 Float@TARGET=SYCL|VECTOR|32BIT|
#4.|If>Multiple>Valid>Solutions>MAX THREE_Exist>>Then>List>Print>>>Preference
#5.|List|briefly|print|Precision-FP16@32-bit|Aligment-Zero-Copy-Focus
\

|04|Beginn|Processing/|EXIT-without-REPEATING!!!

|Add|Section1:Restatement
|And|Section2:Ambiguities-Missing-Info
|And|Section3:Minimal PROOF-of-AnSwer
|And|Section4:Possible-AlternatiVe
|Sol|SUPPRESS_META_COMMENTARY
|Set|ATTRIBUTE_MINIMAL_CONCISE
|CONTROL|IGNORING_EVERYTHING_ELSE
|And|
|EXECUTE|PRINT_ALL_SECTIONS|OUTPUT=SINGLE_SENTENCE|MAX-TEN-SENTENCES|
|TERMINATE
|Fi\|
|MAIN|0-5|ENDE\|"
}

local GPU_ID=$(echo "$ONEAPI_DEVICE_SELECTOR" | awk -F':' '{print $2}')
local NGL_SET=${N_GPU_LAYERS:-99}
local FULL_LLAMA_CLI_PATH="./${BUILD_DIR}/${LLAMA_CLI_PATH}"
#KLEINER EINSTELLEN USE SMALL NUMBERS FOR BETTER AI
local CONTEXT_SIZE=65536
#NEUE WERTE SETZEN 512 1024 2048 Standart4096|0x1000 Empfohlen:8192|0x2000 MathtTutor:16384|0x4000
#Kritisch:24576|0x6000 32768|0x8000|65536|131072|262144|524288|
local PREDICT_TOKENS=524288
local layer=${N_GPU_LAYERS:-99}
local TENSOR_SPLIT=99
local row=99
log "üî∑STARTE KI ANTWORT MIT PARAMETER**${DEVICE}(ID: ${GPU_ID})**NGL WERT GLEICH${NGL_SET}**${FULL_LLAMA_CLI_PATH}**"
if [ ! -x "${FULL_LLAMA_CLI_PATH}" ]; then
error "‚ùåFEHLER AKTUELLER UNTERBAU NEUBAU FEHLGESCHLAGEN${FULL_LLAMA_CLI_PATH}"
return 1
fi
ZES_ENABLE_SYSMAN=1 "${FULL_LLAMA_CLI_PATH}" \
    -no-cnv \
    -m "${MODEL_PATH_ARG}" \
    -p "${PROMPT_ARG}" \
    -n "${PREDICT_TOKENS}" \
    -c "${CONTEXT_SIZE}" \
    -ngl "${N_GPU_LAYERS}" \
    --main-gpu ${GPU_ID}
echo "‚úÖSPRACHMODELL INTERAKTIONS FUNKTION JETZT AKTIV"
}

##--split-mode "${layer}" \
#--tensor-split "${row}" \
##"${env: LLAMA_ARG_SPLIT_MODE}" \
#DEFINITIONHAUPTFUNKTION
main() {
local FP_MODE="${1:-1}"
local RERUN_BUILD=1
prepare_environment
#01
local FULL_LLAMA_CLI_PATH="./${BUILD_DIR}/${LLAMA_CLI_PATH}"
local FULL_LS_PATH="./${BUILD_DIR}/${LS_SYCL_DEVICE_PATH}"
if [[ -f "${FULL_LLAMA_CLI_PATH}" ]] && [[ -f "${FULL_LS_PATH}" ]]; then
success "‚úÖ XAIGPUARC WERKZEUGKASTEN VORHANDEN NEUBAU UNNOETIG**${FULL_LLAMA_CLI_PATH}** **${FULL_LS_PATH}**"
log "üî∑UEBERSPRINGE BAUVORGANG WERKZEUGKASTEN"
RERUN_BUILD=0
else
warn "‚ö†Ô∏èKEIN AKTUELLES XAIGPUARC GEFUNDEN WIRD NEU GEBAUT"
RERUN_BUILD=1
fi
if [[ "$RERUN_BUILD" -eq 1 ]]; then
log "üî∑STARTE ERSTMALIGEN BAUVORGANG XAIGPUARC"
if check_internet; then
log "üî∑LADE WERKZEUGKASTEN"
#0
setup_project
#1
patch_llama_cpp
#2
else
warn "‚ö†Ô∏èINTERNET NICHT VERFUEGBAR UEBERSPRINGE AUFWERTUNG WERKZEUGKASTEN LOKALE VERSION"
fi
fi
configure_build "${FP_MODE}"
#3
compile_project
#4
auto_select_device
#5
list_sycl_devices
#6
prepare_model "${2:-}"
#7
run_inference "${2:-}" "${3:-}"
#8
log "‚úÖNUTZUNG VON XAIGPUARC JETZT MOEGLICH /IHRE FRAGE NACH > ... DRUECKEN SIE |ENTER**${BUILD_DIR}/${LLAMA_CLI_PATH}**"
}
#HAUPTSCHLEIFE
main "${1:-1}" "${2:-}" "${3:-}"
#42
log "‚úÖKOMPLETTER BAUVORGANG HIER GESPEICHERT**${LOG_FILE}**"
